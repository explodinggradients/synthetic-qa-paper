---
# Creating Vector DB
cache:
  cache_dir: formatted_dataset/arc
  cache_docs: true
  cache_chunks: true
  cache_vector_db: true

corpus:
  split_overlap: 0.1
  num_retrievals: 30
  from_file_lines:
    file_path: ../datasets/arc/ARC_Corpus.txt
  # from_hf:
  #   dataset_id: luisespinosa/maec-2020
  #   split: train
  #   column: text

embedding_model:
  hf:
    model_id: thenlper/gte-small
    device: cuda

# RAG
system_prompt: |
  Using the information contained in the context, give a comprehensive answer to the question.
  Respond only to the question asked, response should be concise and relevant to the question.
  If the answer cannot be deduced from the context, do not generate any response on your own.
  Place your response only in the following JSON and do not generate anything else:
  {{
      "found_the_answer": <true or false>,
      "actual_response": <Str>,
      "id_of_relevant_documents": <List(Int)>,
  }}

context_prompt: |
  Context:
  {context}
  ---
  Now here is the question you need to answer.
  {question}

generator_model:
  hf:
    model_id: microsoft/Phi-3-mini-4k-instruct
    trust_remote_code: True
    device: cuda
    torch_dtype: bf16
    max_new_tokens: 1024

reranker:
  num_selections: 4
  model_id: colbert-ir/colbertv2.0